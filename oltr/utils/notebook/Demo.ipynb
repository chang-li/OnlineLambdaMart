{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../../')\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chang/Library/Python/3.7/lib/python/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import Queries\n",
    "from queries import concatenate\n",
    "from queries import find_constant_features\n",
    "\n",
    "from click_simulator import DependentClickModel\n",
    "\n",
    "from utils.metric import ndcg_at_k\n",
    "from utils.utils import evaluate_ranker\n",
    "\n",
    "from rankers.click_lmart_ranker import ClickLMARTRanker\n",
    "from rankers.lmart_ranker import LMARTRanker\n",
    "from learners.online_learner import OnlineLTR\n",
    "from learners.exploit_then_explore import ExploreThenExploitOLTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Queries\n",
    "queries_list = []\n",
    "for name in ['train.txt', 'test.txt', 'vali.txt']:\n",
    "    data_dir = '../../../datasets/MSLR10K/Fold1/' + name\n",
    "    queries = Queries.load_from_text(data_dir)\n",
    "    cls = find_constant_features(queries)\n",
    "    queries.adjust(remove_features=cls, purge=True, scale=True)\n",
    "    queries.save(data_dir[:-3]+'dat')\n",
    "    queries_list.append(queries)\n",
    "query_all = concatenate(queries_list)\n",
    "query_all.save('../../../datasets/MSLR10K.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../datasets/MSLR10K.dat'\n",
    "queries = Queries.load(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_model = DependentClickModel('pure_cascade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_query = len(queries)\n",
    "n_query_used = 10000\n",
    "train_qset = queries[:int(0.4*n_query)][: n_query_used]\n",
    "test_qset = queries[int(0.4*n_query): int(0.8*n_query)][: n_query_used]\n",
    "valid_qset = queries[int(0.8*n_query):][: n_query_used]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmart_ranker_params = {\n",
    "    'min_child_samples': 50,\n",
    "    'min_child_weight': 0,\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_leaves': 400,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'ndcg_eval_at': '5,10',\n",
    "  }\n",
    "lmart_fit_params = {\n",
    "    'eval_metric': 'ndcg',\n",
    "    'eval_at': 10,\n",
    "    'verbose': 50,\n",
    "}\n",
    "\n",
    "eval_params = {\n",
    "    'metric': ndcg_at_k,\n",
    "    'cutoff': 10\n",
    "}\n",
    "\n",
    "num_iterations=10\n",
    "num_train_queries=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's ndcg@10: 0.432306\n",
      "[100]\tvalid_0's ndcg@10: 0.445738\n",
      "[150]\tvalid_0's ndcg@10: 0.45456\n",
      "[200]\tvalid_0's ndcg@10: 0.457156\n",
      "[250]\tvalid_0's ndcg@10: 0.458493\n",
      "[300]\tvalid_0's ndcg@10: 0.458774\n",
      "[350]\tvalid_0's ndcg@10: 0.458793\n",
      "[400]\tvalid_0's ndcg@10: 0.457874\n",
      "[450]\tvalid_0's ndcg@10: 0.458315\n",
      "[500]\tvalid_0's ndcg@10: 0.456499\n",
      "[50]\tvalid_0's ndcg@10: 0.808822\n",
      "[100]\tvalid_0's ndcg@10: 0.807776\n",
      "[150]\tvalid_0's ndcg@10: 0.810022\n",
      "[200]\tvalid_0's ndcg@10: 0.811958\n",
      "[250]\tvalid_0's ndcg@10: 0.817442\n",
      "[300]\tvalid_0's ndcg@10: 0.817626\n",
      "[350]\tvalid_0's ndcg@10: 0.819314\n",
      "[400]\tvalid_0's ndcg@10: 0.820169\n",
      "[450]\tvalid_0's ndcg@10: 0.820915\n",
      "[500]\tvalid_0's ndcg@10: 0.821925\n",
      "[50]\tvalid_0's ndcg@10: 0.707528\n",
      "[100]\tvalid_0's ndcg@10: 0.709955\n",
      "[150]\tvalid_0's ndcg@10: 0.710639\n",
      "[200]\tvalid_0's ndcg@10: 0.7092\n",
      "[250]\tvalid_0's ndcg@10: 0.708837\n",
      "[300]\tvalid_0's ndcg@10: 0.709956\n",
      "[350]\tvalid_0's ndcg@10: 0.711201\n",
      "[400]\tvalid_0's ndcg@10: 0.709317\n",
      "[450]\tvalid_0's ndcg@10: 0.709423\n",
      "[500]\tvalid_0's ndcg@10: 0.708127\n",
      "[50]\tvalid_0's ndcg@10: 0.432306\n",
      "[100]\tvalid_0's ndcg@10: 0.445738\n",
      "[150]\tvalid_0's ndcg@10: 0.45456\n",
      "[200]\tvalid_0's ndcg@10: 0.457156\n",
      "[250]\tvalid_0's ndcg@10: 0.458493\n",
      "[300]\tvalid_0's ndcg@10: 0.458774\n",
      "[350]\tvalid_0's ndcg@10: 0.458793\n",
      "[400]\tvalid_0's ndcg@10: 0.457874\n",
      "[450]\tvalid_0's ndcg@10: 0.458315\n",
      "[500]\tvalid_0's ndcg@10: 0.456499\n"
     ]
    }
   ],
   "source": [
    "rankers = {\n",
    "     'Click LambdaMART': ClickLMARTRanker(\n",
    "      train_qset, valid_qset, test_qset,\n",
    "      lmart_ranker_params, lmart_fit_params, click_model=click_model,\n",
    "      total_number_of_clicked_queries=n_query_used),\n",
    "    'Click LambdaMART Random': ClickLMARTRanker(\n",
    "      train_qset, valid_qset, test_qset,\n",
    "      lmart_ranker_params, lmart_fit_params, click_model=click_model,\n",
    "      total_number_of_clicked_queries=n_query_used, learn_from_random=True),\n",
    "    'Offline LambdaMART': LMARTRanker(\n",
    "      train_qset, valid_qset, test_qset,\n",
    "      lmart_ranker_params, lmart_fit_params),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click LambdaMART 0.156550988378849\n",
      "Click LambdaMART Random 0.3403714564675741\n",
      "Offline LambdaMART 0.47290357213558776\n"
     ]
    }
   ],
   "source": [
    "for ranker in rankers:\n",
    "    print(ranker, evaluate_ranker(test_qset, rankers[ranker], eval_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click LambdaMART 0.14448130143533677\n",
      "Click LambdaMART Random 0.32218318543834934\n",
      "Offline LambdaMART 0.4743506668434501\n"
     ]
    }
   ],
   "source": [
    "for ranker in rankers:\n",
    "    print(ranker, evaluate_ranker(test_qset, rankers[ranker], eval_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1982 0.7984 1.     0.3966 0.    ]\n"
     ]
    }
   ],
   "source": [
    "clicks=[]\n",
    "rk = [1,3,4,2,0]\n",
    "\n",
    "for i in range(10000):\n",
    "    clicks.append(click_model.get_click(rk))\n",
    "print(np.mean(clicks, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = rankers['Click LambdaMART Random']\n",
    "self.click_model = click_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_clicked_queries=10000\n",
    "\"\"\"\n",
    "  Train the ranker on the click training set\n",
    "\"\"\"\n",
    "self.num_training_queries = {\n",
    "    'train': int(.6 * total_number_of_clicked_queries),\n",
    "    'valid': int(.2 * total_number_of_clicked_queries),\n",
    "    'test': int(.2 * total_number_of_clicked_queries),\n",
    "    }\n",
    "self.click_training_data = {}\n",
    "l = {}\n",
    "for data in ['train', 'valid', 'test']:\n",
    "    query_ids, labels, rankings = get_labels_and_rankings(self, self.offline_ranker, self.num_training_queries[data], data)\n",
    "    clicks = self.apply_click_model_to_labels_and_scores(self.click_model,\n",
    "                                                       labels,\n",
    "                                                       rankings)\n",
    "    self.click_training_data[data] = \\\n",
    "    self.generate_training_data_from_clicks(query_ids, clicks,\n",
    "                                            rankings, data)\n",
    "    l[data]=labels\n",
    "features = {}\n",
    "labels_dict = {}\n",
    "query_group = {}\n",
    "for data in ['train', 'valid', 'test']:\n",
    "    indices = self.click_training_data[data][0]\n",
    "    features[data] = np.concatenate([self.offline_qset[data].feature_vectors[idx] for idx in indices])\n",
    "    labels_dict[data] = self.click_training_data[data][1]\n",
    "    query_group[data] = self.click_training_data[data][2]\n",
    "# self.click_ranker.fit(X=features['train'], y=labels['train'],\n",
    "#                       group=query_group['train'],\n",
    "#                       eval_set=[(features['valid'], labels['valid'])],\n",
    "#                       eval_group=[query_group['valid']],\n",
    "#                       **self.fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850 22929 0.16790963408783635\n"
     ]
    }
   ],
   "source": [
    "print(sum(labels_dict['test']), len(labels_dict['test']), sum(labels_dict['test'])/len(labels_dict['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67820 447653\n"
     ]
    }
   ],
   "source": [
    "print(sum(labels_dict['test']), len(labels_dict['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_map = self.click_model.c_prob\n",
    "p_l=[p_map[lq] for lq in l['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67934.40000000008"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([sum(p) for p in p_l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def get_labels_and_rankings(self, ranker, num_queries, data='train'):\n",
    "    \"\"\"Apply a ranker to a subsample of the data and get the labels and ranks.\n",
    "\n",
    "    Args:\n",
    "      ranker: A LightGBM model.\n",
    "      num_queries: Number of queries to be sampled from self.offline_train_qset\n",
    "\n",
    "    Returns:\n",
    "      A tuple of lists that assign labels and rankings to the documents of each\n",
    "      query.\n",
    "    \"\"\"\n",
    "    qset = self.offline_train_qset\n",
    "    if data == 'valid':\n",
    "        qset = self.offline_valid_qset\n",
    "    if data == 'test':\n",
    "        qset = self.offline_test_qset\n",
    "    query_ids = np.arange(len(qset))\n",
    "    n_docs_per_query = [qset[qid].document_count() for qid in query_ids]\n",
    "    indices = [0] + np.cumsum(n_docs_per_query).tolist()\n",
    "    labels = [qset[qid].relevance_scores for qid in query_ids]\n",
    "\n",
    "    # Get the rankings of document per query\n",
    "    if ranker is None:\n",
    "        rankings = [np.random.permutation(n_docs) for n_docs in n_docs_per_query]\n",
    "    else:\n",
    "        features = qset[query_ids].feature_vectors\n",
    "        scores = ranker.predict(features)\n",
    "        tie_breakers = np.random.rand(scores.shape[0])\n",
    "        rankings = [np.lexsort((tie_breakers[indices[i]:indices[i+1]],\n",
    "                              -scores[indices[i]:indices[i+1]]))\n",
    "                  for i in range(len(qset))]\n",
    "\n",
    "    return query_ids, labels, rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.query_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
